{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url: https://tbrain.trendmicro.com.tw/Competitions/Details/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, udf, lag, rank, lit\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global Path\n",
    "if sc.master[0:5]==\"local\":\n",
    "    #Path = \"file:/c:/D Drive/work/bigData/pySpark/TBrain_Round2_DataSet_20180427\"\n",
    "    #Path = \"file:/Users/yungchuanlee/Documents/learn/AI競賽/ETF預測/TBrain_Round2_DataSet_20180427\"\n",
    "    Path = \"file:/home/hduser/app/bigdata/competition/etf/TBrain_Round2_DataSet_20180427\"\n",
    "else:\n",
    "    Path = \"hdfs://master:9000/user/hduser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define alias of columns\n",
    "col_alias_etf= {\"代碼\":\"etf_id\", \"日期\": \"etf_date\", \"中文簡稱\": \"etf_name\", \"開盤價(元)\":\"etf_open\", \n",
    "            \"最高價(元)\":\"etf_high\", \"最低價(元)\":\"etf_low\", \"收盤價(元)\":\"etf_close\", \"成交張數(張)\":\"etf_count\"}\n",
    "col_alias_stock= {\"代碼\":\"stock_id\", \"日期\": \"stock_date\", \"中文簡稱\": \"stock_name\", \"開盤價(元)\":\"stock_open\", \n",
    "            \"最高價(元)\":\"stock_high\", \"最低價(元)\":\"stock_low\", \"收盤價(元)\":\"stock_close\", \"成交張數(張)\":\"stock_count\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf\n",
    "def to_double(str_val):\n",
    "    return float(str_val.replace(\",\",\"\"))\n",
    "to_double=udf(to_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def function to read data (因檔案格式都相同)\n",
    "def read_data(file_name, col_alias):\n",
    "    str_cols = [\"代碼\",\"日期\", \"中文簡稱\"]\n",
    "    raw_data = spark.read.option(\"encoding\", \"Big5\").csv(Path + \"/\" + file_name, header=True, sep=\",\")\n",
    "    print(\"Total \" + file_name + \" count: \" + str(raw_data.count()))\n",
    "    #rename cols and correct type \n",
    "    num_cols = [col_name for col_name in raw_data.columns if col_name not in str_cols]\n",
    "    final_data=raw_data.select( [col(str_col_name).alias(col_alias[str_col_name]) for str_col_name in str_cols] + \n",
    "                                  [to_double(col(num_col_name)).cast(\"double\").alias(col_alias[num_col_name]) for num_col_name in num_cols] )\n",
    "    final_data.printSchema()\n",
    "    final_data.show(5)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting import tetfp.csv(台灣18檔ETF股價資料)...\n",
      "Total tetfp.csv count: 19054\n",
      "root\n",
      " |-- etf_id: string (nullable = true)\n",
      " |-- etf_date: string (nullable = true)\n",
      " |-- etf_name: string (nullable = true)\n",
      " |-- etf_open: double (nullable = true)\n",
      " |-- etf_high: double (nullable = true)\n",
      " |-- etf_low: double (nullable = true)\n",
      " |-- etf_close: double (nullable = true)\n",
      " |-- etf_count: double (nullable = true)\n",
      "\n",
      "+-------+--------+----------------+--------+--------+-------+---------+---------+\n",
      "| etf_id|etf_date|        etf_name|etf_open|etf_high|etf_low|etf_close|etf_count|\n",
      "+-------+--------+----------------+--------+--------+-------+---------+---------+\n",
      "|0050   |20130102|元大台灣50          |    54.0|   54.65|   53.9|     54.4|  16487.0|\n",
      "|0050   |20130103|元大台灣50          |    54.9|   55.05|  54.65|    54.85|  29020.0|\n",
      "|0050   |20130104|元大台灣50          |   54.85|   54.85|   54.4|     54.5|   9837.0|\n",
      "|0050   |20130107|元大台灣50          |   54.55|   54.55|   53.9|    54.25|   8910.0|\n",
      "|0050   |20130108|元大台灣50          |    54.0|    54.2|  53.65|     53.9|  12507.0|\n",
      "+-------+--------+----------------+--------+--------+-------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"starting import tetfp.csv(台灣18檔ETF股價資料)...\")\n",
    "tetfp_dt=read_data(\"tetfp.csv\", col_alias_etf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|            etf_date|\n",
      "+-------+--------------------+\n",
      "|  count|               19054|\n",
      "|   mean|2.0153294704733916E7|\n",
      "| stddev|  15718.272009667517|\n",
      "|    min|            20130102|\n",
      "|    max|            20180427|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "#range of date\n",
    "tetfp_dt.describe('etf_date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.functions import lag, col, avg,collect_list, lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import ArrayType, DoubleType, IntegerType\n",
    "#declare previous row windows\n",
    "wsSpec_etf = Window.partitionBy('etf_id').orderBy('etf_date') #time window for normal case\n",
    "wsSpec_etf_close_price_raw = Window.partitionBy('etf_id').orderBy('row_idx').rangeBetween(-sys.maxsize, -1)\n",
    "wsSpec_etf_dif_raw = Window.partitionBy('etf_id').orderBy('row_idx').rangeBetween(-sys.maxsize, 0)\n",
    "def avg_list(p_list):\n",
    "    #計算數字list的平均值\n",
    "    return sum(p_list)/len(p_list)\n",
    "#計算EMA的udf\n",
    "def calculate_ema_native(close_p_list, window_len):\n",
    "    #透過歷史收盤價計算\n",
    "    if len(close_p_list) < window_len:\n",
    "        return None\n",
    "    elif len(close_p_list) == window_len:\n",
    "        #if len of list = win_len then return avg, \n",
    "        return avg_list(close_p_list)\n",
    "    else:\n",
    "        #else EMA[t] =(EMA[t-1]*(win_len-1)+close[t]*2)/(win_len+1)\n",
    "        ema = avg_list(close_p_list[:window_len])\n",
    "        for price in close_p_list[window_len:]:\n",
    "            ema = (ema*(window_len-1)+price*2)/(window_len+1)\n",
    "        return ema\n",
    "calculate_ema=udf(calculate_ema_native, DoubleType())\n",
    "#計算BIAS的udf\n",
    "def calculate_bias(close_p_list):\n",
    "    #計算前日收盤價與N日均線之差比: (close price - MA)/MA   ,Paper 建議用20日MA\n",
    "    #因要預測今日的收盤價，故計算前日收盤價與前20日均線\n",
    "    if len(close_p_list) < 21:\n",
    "        return None\n",
    "    else:\n",
    "        list_len = len(close_p_list)\n",
    "        p_close = close_p_list[-1]\n",
    "        cal_list = close_p_list[list_len-21: list_len-1]\n",
    "        return p_close - avg_list(cal_list)\n",
    "calculate_bias=udf(calculate_bias, DoubleType())\n",
    "\n",
    "def get_min_max_last(p_list):\n",
    "    #找出list中最大最小和最後一個值, 回傳(min, max, last)\n",
    "    return (min(p_list), max(p_list), p_list[-1])\n",
    "def calculate_raw_rsv(p_list):\n",
    "    #RSV = (收盤價-9日低值)/(9日高值-9日低值)\n",
    "    p_min, p_max, p_last = get_min_max_last(p_list)\n",
    "    rsv = (p_last - p_min)/(p_max - p_min)\n",
    "    return rsv\n",
    "def calculate_rsv(p_9_list, k_prev, d_prev):\n",
    "    #計算加權後的RSV，p_9_list=>9日收盤價\n",
    "    rrsv = calculate_raw_rsv(p_9_list)\n",
    "    k_curr = (1/3)*rrsv + (2/3)*k_prev\n",
    "    d_curr = (1/3)*k_curr + (2/3)*d_prev\n",
    "    return [k_curr, d_curr]\n",
    "#計算隨機指標（Stochastic Oscillator，KD），原名%K&%D\n",
    "def calculate_KD(close_p_list):\n",
    "    win_len = 9 #看過去 9 日值\n",
    "    #RSV = (收盤價-9日低值)/(9日高值-9日低值)\n",
    "    #K_curr = 1/3*RSV + 2/3*K_prev\n",
    "    #D_curr = 1/3*K_curr + 2/3*D_prev\n",
    "    if len(close_p_list) < win_len:\n",
    "        return None\n",
    "    elif len(close_p_list) == win_len:\n",
    "        #無前日K, D時，以0.5帶入\n",
    "        return calculate_rsv(close_p_list, 0.5, 0.5)\n",
    "    else:\n",
    "        kds = calculate_rsv(close_p_list[0:9], 0.5, 0.5)\n",
    "        for idx in range(1, (len(close_p_list)+1-9)):\n",
    "            p_9_list = close_p_list[idx: idx+9]\n",
    "            kds = calculate_rsv(p_9_list, kds[0], kds[1])\n",
    "        return kds\n",
    "calculate_KD=udf(calculate_KD, ArrayType(DoubleType()))\n",
    "\n",
    "#計算差離值DIF = 12日EMA - 26日EMA\n",
    "def calculate_DIF(close_p_list):\n",
    "    if len(close_p_list) < 26:\n",
    "        return None\n",
    "    else:\n",
    "        ema12 = calculate_ema_native(close_p_list, 12)\n",
    "        ema26 = calculate_ema_native(close_p_list, 26)\n",
    "        return ema12 - ema26\n",
    "calculate_DIF=udf(calculate_DIF, DoubleType())\n",
    "\n",
    "#計算MACD=(前一日MACD × (9 - 1) + 今日DIF × 2) ÷ (9 + 1)\n",
    "def calculate_MACD(dif_list, dif_curr):\n",
    "    win_len = 9\n",
    "    if len(dif_list) < win_len:\n",
    "        return None\n",
    "    elif len(dif_list) == win_len:\n",
    "        #if len of list = win_len then return avg, \n",
    "        return avg_list(dif_list)\n",
    "    else:\n",
    "        #MACD=(前一日MACD × (9 - 1) + 今日DIF × 2) ÷ (9 + 1)\n",
    "        macd = avg_list(dif_list[:win_len])\n",
    "        for price in dif_list[win_len:]:\n",
    "            macd = (macd*(win_len-1)+dif_curr*2)/(win_len+1)\n",
    "        return macd\n",
    "calculate_MACD=udf(calculate_MACD, DoubleType())\n",
    "\n",
    "#計算相對強弱指數(RSI)\n",
    "def calculate_RSI(close_p_list):\n",
    "    win_len = 9\n",
    "    if len(close_p_list) < (win_len + 1):\n",
    "        return None\n",
    "    else:\n",
    "        cur_list = close_p_list[1:]\n",
    "        prv_list = close_p_list[0:-1]\n",
    "        p_dif_list = list(map(lambda x,y : x - y, cur_list, prv_list)) #dif list\n",
    "        u_list = []\n",
    "        d_list = []\n",
    "        for dif in p_dif_list:\n",
    "            if dif == 0:\n",
    "                #若兩天價格相同，則U及D皆等於零\n",
    "                u_list.append(0)\n",
    "                d_list.append(0)\n",
    "            elif dif > 0:\n",
    "                #在價格上升的日子, U = diff, D = 0\n",
    "                u_list.append(dif)\n",
    "                d_list.append(0)\n",
    "            else:\n",
    "                #在價格下跌的日子, U = 0, D = abs(diff)\n",
    "                u_list.append(0)\n",
    "                d_list.append(abs(dif))\n",
    "        #RSI = ema(u,9)/(ema(u,9)+ema(d,9))\n",
    "        ema_u = calculate_ema_native(u_list, win_len)\n",
    "        ema_d = calculate_ema_native(d_list, win_len)\n",
    "        return ema_u/(ema_u + ema_d)\n",
    "calculate_RSI=udf(calculate_RSI, DoubleType())\n",
    "\n",
    "#計算威廉指標（Williams %R）\n",
    "def calculate_WR(close_p_list):\n",
    "    win_len = 9\n",
    "    if len(close_p_list) < win_len:\n",
    "        return None\n",
    "    else:\n",
    "        p_list = close_p_list[len(close_p_list) - win_len :]\n",
    "        return 1.0 - calculate_raw_rsv(p_list)\n",
    "calculate_WR=udf(calculate_WR, DoubleType())\n",
    "\n",
    "#計算上或下的值\n",
    "def judge_up_down_native(curr_price, close_p_list):\n",
    "    prev_price = 0.0\n",
    "    if len(close_p_list) < 1:\n",
    "        prev_price = curr_price\n",
    "    if curr_price == prev_price:\n",
    "        return 0.0\n",
    "    elif curr_price > prev_price:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 2.0\n",
    "judge_up_down=udf(judge_up_down_native, DoubleType())\n",
    "\n",
    "#calculate diff between close_price and last_price\n",
    "def calculate_price_diff(curr_price, close_p_list):\n",
    "    if len(close_p_list) < 1:\n",
    "        return None\n",
    "    return abs(curr_price - close_p_list[-1])\n",
    "calculate_price_diff=udf(calculate_price_diff, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- etf_id: string (nullable = true)\n",
      " |-- etf_date: string (nullable = true)\n",
      " |-- etf_name: string (nullable = true)\n",
      " |-- etf_open: double (nullable = true)\n",
      " |-- etf_high: double (nullable = true)\n",
      " |-- etf_low: double (nullable = true)\n",
      " |-- etf_close: double (nullable = true)\n",
      " |-- etf_count: double (nullable = true)\n",
      " |-- row_idx: integer (nullable = true)\n",
      " |-- close_price_raw: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- EMA5: double (nullable = true)\n",
      " |-- EMA10: double (nullable = true)\n",
      " |-- EMA20: double (nullable = true)\n",
      " |-- BIAS: double (nullable = true)\n",
      " |-- KD: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- K: double (nullable = true)\n",
      " |-- D: double (nullable = true)\n",
      " |-- DIF: double (nullable = true)\n",
      " |-- dif_list: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- MACD: double (nullable = true)\n",
      " |-- RSI: double (nullable = true)\n",
      " |-- WR: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate ema [5,10,20] #cannot remove row_idx, row_idx for next window usage\n",
    "tetfp_dt2=tetfp_dt.withColumn(\"row_idx\", rank().over(wsSpec_etf)) \\\n",
    "    .withColumn(\"close_price_raw\", collect_list(col('etf_close')).over(wsSpec_etf_close_price_raw)) \\\n",
    "    .withColumn(\"EMA5\", calculate_ema(col(\"close_price_raw\"), lit(5))) \\\n",
    "    .withColumn(\"EMA10\", calculate_ema(col(\"close_price_raw\"), lit(10))) \\\n",
    "    .withColumn(\"EMA20\", calculate_ema(col(\"close_price_raw\"), lit(20))) \\\n",
    "    .withColumn(\"BIAS\", calculate_bias(col(\"close_price_raw\"))) \\\n",
    "    .withColumn(\"KD\", calculate_KD(col(\"close_price_raw\"))) \\\n",
    "    .withColumn(\"K\", col(\"KD\")[0]).withColumn(\"D\", col(\"KD\")[1]) \\\n",
    "    .withColumn(\"DIF\", calculate_DIF(col(\"close_price_raw\"))) \\\n",
    "    .withColumn(\"dif_list\", collect_list(col('DIF')).over(wsSpec_etf_dif_raw)) \\\n",
    "    .withColumn(\"MACD\", calculate_MACD(col(\"dif_list\"), col(\"DIF\"))) \\\n",
    "    .withColumn(\"RSI\", calculate_RSI(col(\"close_price_raw\")))\\\n",
    "    .withColumn(\"WR\", calculate_WR(col(\"close_price_raw\"))) \\\n",
    "    .withColumn(\"price_dif\", calculate_price_diff(col(\"etf_close\"), col(\"close_price_raw\"))) \\\n",
    "    .withColumn(\"up_down\", judge_up_down(col(\"etf_close\"), col(\"close_price_raw\")))\n",
    "\n",
    "tetfp_dt2.cache()\n",
    "tetfp_dt2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, StandardScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "tot_dt = tetfp_dt2.filter(\"MACD is not null\") \\\n",
    "    .select(\"etf_id\", \"etf_date\", \"EMA5\", \"EMA10\", \"EMA20\", \"BIAS\", \"K\", \"D\", \"DIF\", \"MACD\", \"RSI\", \"WR\", \"etf_close\",\"price_dif\",\"up_down\") \\\n",
    "    .orderBy(\"etf_id\", \"etf_date\", ascending=True)\n",
    "    \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#將Feature合併為Vector 並作標準化\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"EMA5\", \"EMA10\", \"EMA20\", \"BIAS\", \"K\", \"D\", \"DIF\", \"MACD\", \"RSI\", \"WR\"],\n",
    "    outputCol=\"features\")\n",
    "tot_dt_1 = assembler.transform(tot_dt)\n",
    "#minmax_scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"stdFeatures\")\n",
    "std_scaler = StandardScaler(inputCol=\"features\", outputCol=\"stdFeatures\")\n",
    "scaler_model = std_scaler.fit(tot_dt_1)\n",
    "tot_dt_scale = scaler_model.transform(tot_dt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count:  18261 , test count:  181\n",
      "+-------+--------+--------------------+---------+\n",
      "| etf_id|etf_date|         stdFeatures|etf_close|\n",
      "+-------+--------+--------------------+---------+\n",
      "|0050   |20130227|[3.92577832662286...|     55.2|\n",
      "|0050   |20130301|[3.91911915120806...|     55.4|\n",
      "|0050   |20130304|[3.91939685165662...|    54.75|\n",
      "|0050   |20130305|[3.90425124543244...|     55.2|\n",
      "|0050   |20130306|[3.90476776374778...|    55.45|\n",
      "|0050   |20130307|[3.91100854769770...|     55.4|\n",
      "|0050   |20130308|[3.91398978264972...|     55.8|\n",
      "|0050   |20130311|[3.92541157406791...|     55.9|\n",
      "|0050   |20130312|[3.93538467704259...|    55.55|\n",
      "|0050   |20130313|[3.93377839859013...|    55.65|\n",
      "|0050   |20130314|[3.93506612165104...|     55.6|\n",
      "|0050   |20130315|[3.93474531601037...|     55.2|\n",
      "|0050   |20130318|[3.92509714413306...|     54.5|\n",
      "|0050   |20130319|[3.90215500201036...|     54.6|\n",
      "|0050   |20130320|[3.88921881595778...|    54.25|\n",
      "|0050   |20130321|[3.87233967815380...|     54.3|\n",
      "|0050   |20130322|[3.86226620729909...|    54.15|\n",
      "|0050   |20130325|[3.85201269701880...|    54.55|\n",
      "|0050   |20130326|[3.85461132494879...|    54.55|\n",
      "|0050   |20130327|[3.85634374356879...|     54.7|\n",
      "+-------+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------+--------------------+---------+\n",
      "| etf_id|etf_date|         stdFeatures|etf_close|\n",
      "+-------+--------+--------------------+---------+\n",
      "|0050   |20180416|[5.83716546635901...|     82.3|\n",
      "|0050   |20180417|[5.83255116761583...|     81.4|\n",
      "|0050   |20180418|[5.80824779019079...|     81.6|\n",
      "|0050   |20180419|[5.79676268929918...|    82.65|\n",
      "|0050   |20180420|[5.81387099667820...|    80.75|\n",
      "|0050   |20180423|[5.78046360304247...|    79.95|\n",
      "|0050   |20180424|[5.73932340438494...|    79.55|\n",
      "|0050   |20180425|[5.70246230382974...|     79.3|\n",
      "|0050   |20180426|[5.67199179838656...|    79.05|\n",
      "|0050   |20180427|[5.64578168968474...|     79.2|\n",
      "|0051   |20180416|[2.31844792899052...|    33.18|\n",
      "|0051   |20180417|[2.32820725795357...|     33.0|\n",
      "|0051   |20180418|[2.33046804160968...|    32.75|\n",
      "|0051   |20180419|[2.32607879230739...|    33.15|\n",
      "|0051   |20180420|[2.33258692755605...|    33.02|\n",
      "|0051   |20180423|[2.33385953641717...|     33.0|\n",
      "|0051   |20180424|[2.33423622725208...|    32.44|\n",
      "|0051   |20180425|[2.32127933244509...|    32.02|\n",
      "|0051   |20180426|[2.30273538605106...|    31.71|\n",
      "|0051   |20180427|[2.28306117149781...|    32.11|\n",
      "+-------+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#取出4/16~4/27 (共兩週資料作為測試集)\n",
    "train_dt = tot_dt_scale.filter(\"etf_date < '20180416' and MACD is not null\") \\\n",
    "    .select(\"etf_id\", \"etf_date\", \"stdFeatures\", \"price_dif\",\"up_down\") \\\n",
    "    .orderBy(\"etf_id\", \"etf_date\", ascending=True)\n",
    "test_dt = tot_dt_scale.filter(\"etf_date >= '20180416'\") \\\n",
    "    .select(\"etf_id\", \"etf_date\", \"stdFeatures\", \"price_dif\",\"up_down\") \\\n",
    "    .orderBy(\"etf_id\", \"etf_date\", ascending=True)\n",
    "print('train count: ', str(train_dt.count()), ', test count: ', str(test_dt.count()))\n",
    "train_dt.show(10)\n",
    "test_dt.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00701  ',\n",
       " '0051   ',\n",
       " '0057   ',\n",
       " '006203 ',\n",
       " '0052   ',\n",
       " '0050   ',\n",
       " '0055   ',\n",
       " '0054   ',\n",
       " '0059   ',\n",
       " '00690  ',\n",
       " '00713  ',\n",
       " '006204 ',\n",
       " '006208 ',\n",
       " '0053   ',\n",
       " '006201 ',\n",
       " '0056   ',\n",
       " '00692  ',\n",
       " '0058   ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取出etf的distinct id\n",
    "etf_ids = []\n",
    "for row in test_dt.select(\"etf_id\").distinct().collect():\n",
    "    etf_ids.append(row[\"etf_id\"])\n",
    "etf_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+---------+------------------+\n",
      "| etf_id|etf_date|         stdFeatures|etf_close|        prediction|\n",
      "+-------+--------+--------------------+---------+------------------+\n",
      "|00701  |20180416|[1.50074243200647...|    21.21|21.206789696986018|\n",
      "|00701  |20180417|[1.50074878906728...|    20.95|21.174685121822623|\n",
      "|00701  |20180418|[1.49462073116519...|    21.04|21.008363428238425|\n",
      "|00701  |20180419|[1.49265807705676...|    21.32|21.025511047286045|\n",
      "|00701  |20180420|[1.49795365199961...|     21.0|21.207956363652684|\n",
      "|00701  |20180423|[1.49393659413469...|    20.92|20.974676198801195|\n",
      "|00701  |20180424|[1.48937169526803...|    20.88|20.973593406593405|\n",
      "|00701  |20180425|[1.48538499921191...|    20.81|20.819361263736265|\n",
      "|00701  |20180426|[1.48107619908738...|    20.75|20.701266025641026|\n",
      "|00701  |20180427|[1.47678852045350...|    20.86|20.530458333333335|\n",
      "+-------+--------+--------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.597397\n"
     ]
    }
   ],
   "source": [
    "#訓練Model及評估(RandomForestRegressor)\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "rf = RandomForestClassifier(featuresCol=\"stdFeatures\",labelCol=\"up_down\")\n",
    "predit_res = None\n",
    "for etfid in etf_ids:\n",
    "    train_data = train_dt.filter(\"etf_id='\" + etfid + \"'\")\n",
    "    test_data = test_dt.filter(\"etf_id='\" + etfid + \"'\")\n",
    "    rf_model = rf.fit(train_data)\n",
    "    predicts = rf_model.transform(test_data)\n",
    "    if predit_res is None:\n",
    "        predit_res = predicts\n",
    "    else:\n",
    "        predit_res = predit_res.unionAll(predicts)\n",
    "predit_res.show(10)\n",
    "#評估RMES\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"etf_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predit_res)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- etf_id: string (nullable = true)\n",
      " |-- etf_date: string (nullable = true)\n",
      " |-- stdFeatures: vector (nullable = true)\n",
      " |-- etf_close: double (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- prev_close: double (nullable = true)\n",
      " |-- prev_pred_close: double (nullable = true)\n",
      " |-- act_ud: double (nullable = true)\n",
      " |-- pred_ud: double (nullable = true)\n",
      "\n",
      "+-------+--------+---------+----------+------------------+------+-------+\n",
      "| etf_id|etf_date|etf_close|prev_close|        prediction|act_ud|pred_ud|\n",
      "+-------+--------+---------+----------+------------------+------+-------+\n",
      "|00701  |20180416|    21.21|      null|21.206789696986018|   0.0|    0.0|\n",
      "|00701  |20180417|    20.95|     21.21|21.174685121822623|   2.0|    2.0|\n",
      "|00701  |20180418|    21.04|     20.95|21.008363428238425|   1.0|    2.0|\n",
      "|00701  |20180419|    21.32|     21.04|21.025511047286045|   1.0|    1.0|\n",
      "|00701  |20180420|     21.0|     21.32|21.207956363652684|   2.0|    1.0|\n",
      "|00701  |20180423|    20.92|      21.0|20.974676198801195|   2.0|    2.0|\n",
      "|00701  |20180424|    20.88|     20.92|20.973593406593405|   2.0|    2.0|\n",
      "|00701  |20180425|    20.81|     20.88|20.819361263736265|   2.0|    2.0|\n",
      "|00701  |20180426|    20.75|     20.81|20.701266025641026|   2.0|    2.0|\n",
      "|00701  |20180427|    20.86|     20.75|20.530458333333335|   1.0|    2.0|\n",
      "+-------+--------+---------+----------+------------------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test Error = 0.486188 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#計算上或下的值\n",
    "def judge_up_down_native(curr_price, prev_price):\n",
    "    if prev_price is None:\n",
    "        return 0.0\n",
    "    elif curr_price == prev_price:\n",
    "        return 0.0\n",
    "    elif curr_price > prev_price:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 2.0\n",
    "judge_up_down=udf(judge_up_down_native, DoubleType())\n",
    "\n",
    "predit_res_2 = predit_res.withColumn(\"prev_close\", lag(\"etf_close\").over(wsSpec_etf)) \\\n",
    "    .withColumn(\"prev_pred_close\", lag(\"prediction\").over(wsSpec_etf)) \\\n",
    "    .withColumn(\"act_ud\", judge_up_down(col(\"etf_close\"), col(\"prev_close\"))) \\\n",
    "    .withColumn(\"pred_ud\", judge_up_down(col(\"prediction\"), col(\"prev_pred_close\")))\n",
    "predit_res_2.printSchema()\n",
    "predit_res_2.select(\"etf_id\", \"etf_date\", \"etf_close\", \"prev_close\", \"prediction\", \"act_ud\", \"pred_ud\").show(10)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"act_ud\", predictionCol=\"pred_ud\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predit_res_2)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+---------+------------------+\n",
      "| etf_id|etf_date|         stdFeatures|etf_close|        prediction|\n",
      "+-------+--------+--------------------+---------+------------------+\n",
      "|00701  |20180416|[1.50074243200647...|    21.21|21.206789696986018|\n",
      "|00701  |20180417|[1.50074878906728...|    20.95|21.174685121822623|\n",
      "|00701  |20180418|[1.49462073116519...|    21.04|21.008363428238425|\n",
      "|00701  |20180419|[1.49265807705676...|    21.32|21.025511047286045|\n",
      "|00701  |20180420|[1.49795365199961...|     21.0|21.207956363652684|\n",
      "|00701  |20180423|[1.49393659413469...|    20.92|20.974676198801195|\n",
      "|00701  |20180424|[1.48937169526803...|    20.88|20.973593406593405|\n",
      "|00701  |20180425|[1.48538499921191...|    20.81|20.819361263736265|\n",
      "|00701  |20180426|[1.48107619908738...|    20.75|20.701266025641026|\n",
      "|00701  |20180427|[1.47678852045350...|    20.86|20.530458333333335|\n",
      "+-------+--------+--------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.597397\n"
     ]
    }
   ],
   "source": [
    "#訓練Model及評估(GBTRegressor)\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "rf = GBTRegressor(featuresCol=\"stdFeatures\",labelCol=\"etf_close\")\n",
    "predit_res = None\n",
    "for etfid in etf_ids:\n",
    "    train_data = train_dt.filter(\"etf_id='\" + etfid + \"'\")\n",
    "    test_data = test_dt.filter(\"etf_id='\" + etfid + \"'\")\n",
    "    rf_model = rf.fit(train_data)\n",
    "    predicts = rf_model.transform(test_data)\n",
    "    if predit_res is None:\n",
    "        predit_res = predicts\n",
    "    else:\n",
    "        predit_res = predit_res.unionAll(predicts)\n",
    "predit_res.show(10)\n",
    "#評估RMES\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"etf_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predit_res)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll = [46.92, 47.31, 47.0, 46.79, 46.49, 46.66, 47.0, 46.96, 47.0]\n",
    "ll = [46.92, 47.31, 47.0, 46.79, 46.49, 46.66]\n",
    "win_len=5\n",
    "print(ll[1:])\n",
    "print(ll[0: -1])\n",
    "print(list(map(lambda x,y : x - y, ll[1:], ll[0: -1])))\n",
    "for x in ll[win_len:]:\n",
    "    print(x)\n",
    "ema = sum(ll[:win_len])/len(ll[:win_len])\n",
    "print(ema)\n",
    "for price in ll[win_len:]:\n",
    "    ema = (ema*(win_len-1)+price*2)/(win_len+1)\n",
    "tup1, tup2 = (1,2)\n",
    "print(tup1, ' ', tup2)\n",
    "tup = (3,4)\n",
    "print(tup[0], ' ', tup[1])\n",
    "list(range(0,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
